우리 뇌는 Music & Voice에서 감정/가수의 음색/ 톤 등을 어떻게 인지하는가?

-> 음색[=톤] 
-> 감정 인식 

필요한 것들: 

멜-스펙트로그램
how to extract?[어떻게 추출하는가?]: by Librosa[파이썬 음성 분석 패키지]

뇌와 연관짓기: 
- 우리 뇌의 청각을 다루는 메커니즘은 달팽이관을 통해 음파를 일종의 주파수 영역으로 보고 주파수 축의 음파를 받아들이고 이를 통해서 귀에서 뇌로 전기 신호를 보내지는 형식이다. 
- 음성 신호 데이터를 전처리하는 과정에서 Fourier Transform 기반의 Spectrogram이라고 하는 y축을 주파수 성분의 정도, x축을 시간 축으로 하는 그래프를 만들 수 있다. 그리고 이를 적절한 log-scale 변환을 취하면 실제로 우리 뇌에 보내기 위한 달팽이관이 음성 신호를 인지하는 것과 거의 유사한 모양의 그래프 데이터인 Mel-Spectrogram을 얻을 수 있다. 이러한 전처리 과정을 통해서 음성 신호를 실제로 달팽이관을 통해 우리 뇌가 받아들이기 위한 신호와 비슷하게 변경해주어 이를 딥러닝 모델을 통해 hidden Layer로 보내고 우리가 원하는 작업(가수가 누구인가?, 노래의 장르가 무엇인가?, 어떠한 장르인가? 등)에 맞게 Output을 추출하게 할 수 있을 것이다. 그리고 이런 과정들은 실제로 우리 뇌에서 감정이나 톤 등을 느끼는 메커니즘을 일종의 반복적인 경험[=학습]을 통해 깨닫는 것과 매우 유사하게 여길 수 있을 것이다. 




 
 